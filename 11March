Q1: What is the difference between a t-test and a z-test? Provide an example scenario where you would use each type of test.
The t-test and z-test are both statistical hypothesis tests used to compare means between two groups or to test a sample mean against a known population mean. However, they differ in terms of the assumptions they make about the data and the situations in which they are applicable.

Z-test:

Assumption: The z-test assumes that the population standard deviation is known or that the sample size is large enough (usually considered when the sample size is greater than 30) to approximate the population standard deviation with the sample standard deviation.

Applicability: The z-test is commonly used when you have a large sample size and know the population standard deviation. It is generally employed when analyzing normally distributed data.

Example scenario: Suppose you want to test if the mean height of a specific group of students is significantly different from the national average height of students. If the national average height's standard deviation is known and the sample size of the group is sufficiently large (say, greater than 30), you can use a z-test to determine if there's a statistically significant difference.

T-test:

Assumption: The t-test assumes that the population standard deviation is unknown and must be estimated using the sample data. It also assumes that the data are approximately normally distributed.

Applicability: The t-test is used when you have a small sample size or when the population standard deviation is unknown. It is more robust for smaller sample sizes and is widely used in research and experiments.

Example scenario: Let's say you want to compare the effectiveness of two different medications in reducing blood pressure. You have two groups of participants, one for each medication. Since the population standard deviation is unknown and the sample size might not be very large, you would use a t-test to compare the means of the two groups and determine if there's a significant difference in their effectiveness.

In summary, use a z-test when you have a large sample size and know the population standard deviation, and use a t-test when you have a small sample size or don't know the population standard deviation. Always consider the assumptions of each test before applying them to your data.

Q2: Differentiate between one-tailed and two-tailed tests.
One-tailed and two-tailed tests are types of hypothesis tests used in statistical analysis to determine whether there is a significant difference between a sample statistic (e.g., mean or proportion) and a hypothesized value. The main difference between these two types of tests lies in the directionality of the alternative hypothesis.

One-tailed test:

Also known as a directional test.

The alternative hypothesis specifies a particular direction of the effect or difference. It is used when you are interested in whether the sample statistic is significantly greater than or less than the hypothesized value, but not both.

The critical region is located on only one side of the sampling distribution (either the right or the left, depending on the direction specified in the alternative hypothesis).

Example: Suppose a researcher wants to test whether a new teaching method increases students' test scores. The null hypothesis (H0) would state that there is no significant difference in test scores between the new teaching method and the old method. The alternative hypothesis (Ha) would be one-tailed, specifying that the new teaching method increases test scores (Ha: μ_new > μ_old).

Two-tailed test:

Also known as a non-directional test.

The alternative hypothesis does not specify a particular direction of the effect or difference but only that there is a significant difference between the sample statistic and the hypothesized value. It is used when you are interested in whether the sample statistic is significantly different from the hypothesized value, regardless of the direction.

The critical region is located on both sides of the sampling distribution (both the left and the right).

Example: Consider a scenario where a company claims that their product has an average weight of 500 grams. A quality control analyst wants to test this claim. The null hypothesis (H0) would be that the product's average weight is 500 grams (μ = 500). The alternative hypothesis (Ha) would be two-tailed, indicating that the product's average weight is different from 500 grams (Ha: μ ≠ 500).

In summary, a one-tailed test is used when you have a specific direction in mind for the effect or difference you want to test, while a two-tailed test is used when you want to determine if there is a significant difference, regardless of the direction. The choice between the two depends on the research question and the specific hypothesis being tested.

Q3: Explain the concept of Type 1 and Type 2 errors in hypothesis testing. Provide an example scenario for each type of error.
Type 1 and Type 2 errors are two types of errors that can occur in hypothesis testing. These errors are related to the decision-making process when testing a null hypothesis (H0) against an alternative hypothesis (Ha).

Type 1 Error (False Positive):

Definition: A Type 1 error occurs when we reject a true null hypothesis (H0) when it is actually correct. In other words, we mistakenly conclude that there is a significant effect or difference when there is none in the population.

Probability denoted as α (alpha), which is the significance level of the test (typically set at 0.05 or 0.01).

Example scenario: Let's consider a criminal trial. The null hypothesis (H0) in this case would be that the defendant is innocent. The alternative hypothesis (Ha) would be that the defendant is guilty. A Type 1 error occurs if the jury convicts the defendant (rejects the null hypothesis) when, in reality, the defendant is innocent (the null hypothesis is true).

Type 2 Error (False Negative):

Definition: A Type 2 error occurs when we fail to reject a false null hypothesis (H0) when it is actually false. In other words, we miss detecting a significant effect or difference that exists in the population.

Probability denoted as β (beta), which depends on the power of the test (Power = 1 - β).

Example scenario: Consider a medical test for a specific disease. The null hypothesis (H0) would be that the patient does not have the disease. The alternative hypothesis (Ha) would be that the patient has the disease. A Type 2 error occurs if the medical test indicates that the patient does not have the disease (fails to reject the null hypothesis) when, in reality, the patient does have the disease (the null hypothesis is false).

In summary:

Type 1 error (False Positive): Rejecting a true null hypothesis.

Type 2 error (False Negative): Failing to reject a false null hypothesis.

It's important to note that these two types of errors are inversely related. Reducing the risk of one type of error typically increases the risk of the other. Researchers and analysts need to strike a balance between these errors by choosing appropriate sample sizes, significance levels, and statistical power based on the importance of the decision and the consequences of making incorrect conclusions.

Q4: Explain Bayes's theorem with an example.
Bayes's theorem is a fundamental concept in probability theory and statistics that allows us to update our beliefs or probabilities about an event based on new evidence or information. It helps us calculate the probability of a hypothesis (event) being true, given some observed evidence. The theorem is named after the Reverend Thomas Bayes, who first formulated it.

def bayes_theorem(prior_prob, likelihood, evidence):
    # Calculate the posterior probability using Bayes's theorem
    posterior_prob = (likelihood * prior_prob) / evidence
    return posterior_prob

# Given data
prior_probability_disease = 0.01  # Prior probability of a person having the disease (1%)
sensitivity = 0.95  # Probability of a positive test result given the person has the disease (95%)
specificity = 0.90  # Probability of a negative test result given the person does not have the disease (90%)
total_population = 100000  # Total number of people in the population

# Calculate the probability of a positive test result (evidence)
# P(positive test) = P(positive test | disease) * P(disease) + P(positive test | no disease) * P(no disease)
evidence_positive_test = (sensitivity * prior_probability_disease) + ((1 - specificity) * (1 - prior_probability_disease))

# Calculate the probability of having the disease given a positive test result
posterior_probability_disease = bayes_theorem(prior_probability_disease, sensitivity, evidence_positive_test)

print(f"The probability of having the disease given a positive test result is: {posterior_probability_disease:.4f}")
The probability of having the disease given a positive test result is: 0.0876
Q5: What is a confidence interval? How to calculate the confidence interval, explain with an example.
A confidence interval is a range of values within which we are reasonably confident that the true population parameter lies. It provides a measure of the uncertainty associated with estimating a population parameter based on a sample from that population. The confidence interval is typically represented by two values, an upper limit, and a lower limit, along with a specified level of confidence.

For example, if we calculate a 95% confidence interval for the mean of a population, it means that we are 95% confident that the true population mean falls within the calculated range.

To calculate the confidence interval, we need the following information:

Sample mean (x̄): The mean of the sample.

Sample standard deviation (s): The standard deviation of the sample.

Sample size (n): The number of observations in the sample.

Confidence level (1 - α): The level of confidence, typically expressed as a percentage.

import numpy as np
import scipy.stats as stats

# Sample data (example)
sample_data = [25, 30, 35, 40, 45]

# Calculate sample statistics
sample_mean = np.mean(sample_data)
sample_std_dev = np.std(sample_data, ddof=1)  # ddof=1 for sample standard deviation
sample_size = len(sample_data)

# Specify the confidence level (95% confidence level)
confidence_level = 0.95

# Calculate the critical value (Z) based on the confidence level
critical_value = stats.t.ppf((1 + confidence_level) / 2, df=sample_size - 1)

# Calculate the margin of error
margin_of_error = critical_value * (sample_std_dev / np.sqrt(sample_size))

# Calculate the confidence interval
lower_bound = sample_mean - margin_of_error
upper_bound = sample_mean + margin_of_error

print(f"Sample mean: {sample_mean:.2f}")
print(f"95% Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})")
Sample mean: 35.00
95% Confidence Interval: (25.18, 44.82)
Q6. Use Bayes' Theorem to calculate the probability of an event occurring given prior knowledge of the event's probability and new evidence. Provide a sample problem and solution.
def bayes_theorem(prior_prob, likelihood, evidence):
    # Calculate the posterior probability using Bayes's theorem
    posterior_prob = (likelihood * prior_prob) / evidence
    return posterior_prob

# Given data
prior_probability_defective = 0.05 
sensitivity = 0.90 
specificity = 1.0  

# Calculate the probability of a failed inspection (evidence)
# P(failed inspection) = P(failed inspection | defective) * P(defective) + P(failed inspection | not defective) * P(not defective)
evidence_failed_inspection = (sensitivity * prior_probability_defective) + ((1 - specificity) * (1 - prior_probability_defective))

# Calculate the probability of the light bulb being defective given a failed inspection
posterior_probability_defective = bayes_theorem(prior_probability_defective, sensitivity, evidence_failed_inspection)

print(f"The probability of the light bulb being defective given a failed inspection is: {posterior_probability_defective:.4f}")
The probability of the light bulb being defective given a failed inspection is: 1.0000
Q7. Calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5. Interpret the results.
import scipy.stats as stats

# Given data
sample_mean = 50
sample_std_dev = 5
sample_size = 100  # Assuming the sample size is 100 (you can change it as per your actual data)

# Specify the confidence level (95% confidence level)
confidence_level = 0.95

# Calculate the critical value (Z) based on the confidence level
critical_value = stats.norm.ppf((1 + confidence_level) / 2)

# Calculate the margin of error
margin_of_error = critical_value * (sample_std_dev / (sample_size ** 0.5))

# Calculate the confidence interval
lower_bound = sample_mean - margin_of_error
upper_bound = sample_mean + margin_of_error

print(f"Sample mean: {sample_mean}")
print(f"95% Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})")
Sample mean: 50
95% Confidence Interval: (49.02, 50.98)
Q8. What is the margin of error in a confidence interval? How does sample size affect the margin of error? Provide an example of a scenario where a larger sample size would result in a smaller margin of error.
The margin of error (MOE) in a confidence interval is the range of values around the point estimate (e.g., sample mean) that represents the uncertainty or variability in the estimate. It quantifies how much the point estimate might vary from the true population parameter. A larger margin of error indicates greater uncertainty in the estimate, while a smaller margin of error suggests higher precision in the estimate.

The margin of error is influenced by several factors, including the following:

Sample size (n): A larger sample size generally leads to a smaller margin of error because having more data points provides more information about the population, leading to a more precise estimate.

Standard deviation (σ) or standard error (SE): A higher standard deviation or standard error results in a larger margin of error because it indicates more variability in the data.

Confidence level: A higher confidence level (e.g., 95% vs. 99%) leads to a larger margin of error because it requires a wider interval to be more confident in capturing the true population parameter.

import numpy as np

# Population parameters (assumed to be known for simulation purposes)
population_mean_height = 160  # Mean height of students in centimeters
population_std_dev = 10  # Population standard deviation

# Generate the population data (normally distributed heights)
np.random.seed(42)  # For reproducibility
population_data = np.random.normal(loc=population_mean_height, scale=population_std_dev, size=10000)

# Sample size scenarios to compare
sample_sizes = [30, 100, 500, 1000]

# Calculate the margin of error for each sample size
for sample_size in sample_sizes:
    sample_data = np.random.choice(population_data, size=sample_size, replace=False)
    sample_mean = np.mean(sample_data)
    standard_error = population_std_dev / np.sqrt(sample_size)
    z_critical = 1.96  # For a 95% confidence level
    margin_of_error = z_critical * standard_error
    confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)

    print(f"Sample size: {sample_size}")
    print(f"Margin of Error: {margin_of_error:.2f}")
    print(f"95% Confidence Interval: ({confidence_interval[0]:.2f}, {confidence_interval[1]:.2f})\n")
Sample size: 30
Margin of Error: 3.58
95% Confidence Interval: (157.15, 164.31)

Sample size: 100
Margin of Error: 1.96
95% Confidence Interval: (157.86, 161.78)

Sample size: 500
Margin of Error: 0.88
95% Confidence Interval: (159.63, 161.38)

Sample size: 1000
Margin of Error: 0.62
95% Confidence Interval: (159.66, 160.90)

Q9. Calculate the z-score for a data point with a value of 75, a population mean of 70, and a population standard deviation of 5. Interpret the results.
# Given data
data_point = 75
population_mean = 70
population_std_dev = 5

# Calculate the z-score
z_score = (data_point - population_mean) / population_std_dev

print(f"The z-score for the data point is: {z_score:.2f}")
The z-score for the data point is: 1.00
Q10. In a study of the effectiveness of a new weight loss drug, a sample of 50 participants lost an average of 6 pounds with a standard deviation of 2.5 pounds. Conduct a hypothesis test to determine if the drug is significantly effective at a 95% confidence level using a t-test.
import scipy.stats as stats

# Given data
sample_mean = 6
sample_std_dev = 2.5
sample_size = 50
null_hypothesis_mean = 0

# Calculate the t-statistic
standard_error = sample_std_dev / (sample_size ** 0.5)
t_statistic = (sample_mean - null_hypothesis_mean) / standard_error

# Calculate the degrees of freedom for the t-distribution
degrees_of_freedom = sample_size - 1

# Calculate the p-value for a one-tailed test (upper tail)
p_value = 1 - stats.t.cdf(t_statistic, df=degrees_of_freedom)

print(f"t-statistic: {t_statistic:.2f}")
print(f"p-value: {p_value:.4f}")
t-statistic: 16.97
p-value: 0.0000
Q11. In a survey of 500 people, 65% reported being satisfied with their current job. Calculate the 95% confidence interval for the true proportion of people who are satisfied with their job.
import scipy.stats as stats

# Given data
sample_proportion = 0.65  # 65% reported being satisfied with their job
sample_size = 500

# Specify the confidence level (95% confidence level)
confidence_level = 0.95

# Calculate the critical value (Z) based on the confidence level
critical_value = stats.norm.ppf((1 + confidence_level) / 2)

# Calculate the standard error of the proportion
standard_error = (sample_proportion * (1 - sample_proportion) / sample_size) ** 0.5

# Calculate the margin of error
margin_of_error = critical_value * standard_error

# Calculate the confidence interval
lower_bound = sample_proportion - margin_of_error
upper_bound = sample_proportion + margin_of_error

print(f"Sample proportion: {sample_proportion:.2f}")
print(f"95% Confidence Interval: ({lower_bound:.4f}, {upper_bound:.4f})")
Sample proportion: 0.65
95% Confidence Interval: (0.6082, 0.6918)
Q12. A researcher is testing the effectiveness of two different teaching methods on student performance. Sample A has a mean score of 85 with a standard deviation of 6, while sample B has a mean score of 82 with a standard deviation of 5. Conduct a hypothesis test to determine if the two teaching methods have a significant difference in student performance using a t-test with a significance level of 0.01.
import scipy.stats as stats

# Given data for Sample A
mean_sample_a = 85
std_dev_sample_a = 6
sample_size_a = 55 # You need to provide the sample size for Sample A

# Given data for Sample B
mean_sample_b = 82
std_dev_sample_b = 5
sample_size_b = 66  # You need to provide the sample size for Sample B

# Conduct the t-test
t_statistic, p_value = stats.ttest_ind_from_stats(mean_sample_a, std_dev_sample_a, sample_size_a,
                                                 mean_sample_b, std_dev_sample_b, sample_size_b)

# Assuming unequal variances in the two samples (Welch's t-test)

# Determine the significance level (alpha)
alpha = 0.01

# Check if the p-value is less than the significance level
if p_value < alpha:
    print("Reject the null hypothesis: There is a significant difference in student performance between the two teaching methods.")
else:
    print("Fail to reject the null hypothesis: There is no significant difference in student performance between the two teaching methods.")
Reject the null hypothesis: There is a significant difference in student performance between the two teaching methods.
Q13. A population has a mean of 60 and a standard deviation of 8. A sample of 50 observations has a mean of 65. Calculate the 90% confidence interval for the true population mean.
# Given data
sample_mean = 65
population_std_dev = 8
sample_size = 50

# Specify the confidence level (90% confidence level)
confidence_level = 0.90

# Calculate the critical value (Z) based on the confidence level
critical_value = stats.norm.ppf((1 + confidence_level) / 2)

# Calculate the margin of error
margin_of_error = critical_value * (population_std_dev / (sample_size ** 0.5))

# Calculate the confidence interval
lower_bound = sample_mean - margin_of_error
upper_bound = sample_mean + margin_of_error

print(f"Sample mean: {sample_mean}")
print(f"90% Confidence Interval: ({lower_bound:.4f}, {upper_bound:.4f})")
Sample mean: 65
90% Confidence Interval: (63.1391, 66.8609)
Q14. In a study of the effects of caffeine on reaction time, a sample of 30 participants had an average reaction time of 0.25 seconds with a standard deviation of 0.05 seconds. Conduct a hypothesis test to determine if the caffeine has a significant effect on reaction time at a 90% confidence level using a t-test.
import scipy.stats as stats

# Given data
sample_mean = 0.25
sample_std_dev = 0.05
sample_size = 30
null_hypothesis_mean = 0  # Assuming no effect of caffeine, so the null hypothesis mean is 0

# Conduct the t-test
t_statistic, p_value = stats.ttest_1samp([sample_mean] * sample_size, popmean=null_hypothesis_mean)

# Determine the significance level (alpha)
alpha = 0.10

# Check if the p-value is less than the significance level
if p_value < alpha:
    print("Reject the null hypothesis: Caffeine has a significant effect on reaction time.")
else:
    print("Fail to reject the null hypothesis: Caffeine does not have a significant effect on reaction time.")
Reject the null hypothesis: Caffeine has a significant effect on reaction time.
/tmp/ipykernel_2094/3685500120.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  t_statistic, p_value = stats.ttest_1samp([sample_mean] * sample_size, popmean=null_hypothesis_mean)
